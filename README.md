# Image Captioning with CNN & LSTM

![Python](https://img.shields.io/badge/Python-3.10-3776AB)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15-FF6F00)
![Keras](https://img.shields.io/badge/Keras-Deep%20Learning-D00000)
![Status](https://img.shields.io/badge/Status-Completed-success)

## Project Description
This project implements an image captioning model that automatically generates descriptive captions for images using Deep Learning techniques. The architecture is based on the **"Show and Tell"** model, combining Computer Vision and Natural Language Processing.

### Key Features
* **Encoder (Image Processing):** Uses a pre-trained **VGG16** model (Transfer Learning) to extract feature vectors from images.
* **Decoder (Language Modeling):** Uses **LSTM** (Long Short-Term Memory) layers to generate sequence data and handle long-term dependencies.
* **Dataset:** Trained on the **Flickr8k** dataset containing 8,000+ images and 40,000+ captions.

### Model Performance
The model was trained for 20 epochs on a Tesla T4 GPU.
* **Final Loss:** 2.21
* **Optimization:** Adam Optimizer with Categorical Crossentropy loss function.

### Test Results
Below are predictions made by the model on unseen test data:

| Image | 
| :---: | 
| <img width="685" height="380" alt="Ekran Resmi 2025-11-26 20 03 39" src="https://github.com/user-attachments/assets/476b4395-f726-46d2-a666-5096ddcdb1d6" />
 | **"brown dog shaking his head while standing on the sand"**<br>_Demonstrates dynamic action detection._ |
| <img width="658" height="380" alt="Ekran Resmi 2025-11-26 20 02 23" src="https://github.com/user-attachments/assets/dd78fba1-4282-40c8-bada-a0c80299da16" />
| **"group of people are standing on the beach with camels"**<br>_Demonstrates complex scene understanding._ |

---

## Proje AÃ§Ä±klamasÄ±
Bu proje, Derin Ã–ÄŸrenme yÃ¶ntemleri kullanÄ±larak gÃ¶rsellerden otomatik olarak anlamlÄ± Ä°ngilizce aÃ§Ä±klamalar (altyazÄ±lar) Ã¼reten bir yapay zeka sistemidir. Proje, Ostim Teknik Ãœniversitesi Derin Ã–ÄŸrenme dersi kapsamÄ±nda geliÅŸtirilmiÅŸtir.

### Temel Ã–zellikler
* **KodlayÄ±cÄ± (Encoder):** GÃ¶rÃ¼ntÃ¼lerden Ã¶znitelik Ã§Ä±karmak iÃ§in ImageNet Ã¼zerinde eÄŸitilmiÅŸ **VGG16** modeli kullanÄ±lmÄ±ÅŸtÄ±r.
* **Ã‡Ã¶zÃ¼cÃ¼ (Decoder):** Kelime dizilerini Ã¼retmek ve baÄŸlamÄ± korumak iÃ§in **LSTM** aÄŸlarÄ± kullanÄ±lmÄ±ÅŸtÄ±r.
* **Veri Seti:** 8.000'den fazla gÃ¶rÃ¼ntÃ¼ iÃ§eren Flickr8k veri seti kullanÄ±lmÄ±ÅŸtÄ±r.

### Model BaÅŸarÄ±mÄ±
Model, Tesla T4 GPU Ã¼zerinde 20 Epoch boyunca eÄŸitilmiÅŸtir.
* **EÄŸitim KaybÄ± (Loss):** 2.21
* **YÃ¶ntem:** CNN Ã¶zellik vektÃ¶rleri ile LSTM kelime gÃ¶mÃ¼leri (embeddings) birleÅŸtirilerek (Merge Architecture) eÄŸitilmiÅŸtir.

## ğŸ“‚ Kurulum ve KullanÄ±m (Installation)

Projeyi Ã§alÄ±ÅŸtÄ±rmak iÃ§in iki seÃ§eneÄŸiniz var:

### SeÃ§enek 1: Sadece Test Etmek Ä°Ã§in (Ã–nerilen)
EÄŸitim yapmadan, hazÄ±r modeli kullanarak tahmin yapmak iÃ§in:
1. `Demo_Test.ipynb` dosyasÄ±nÄ± Google Colab'de aÃ§Ä±n.
2. Dosyalar arasÄ±ndan `final_model.h5` ve `tokenizer.pkl` dosyalarÄ±nÄ± indirin ve kodda belirtilen yola koyun.
3. HÃ¼creleri Ã§alÄ±ÅŸtÄ±rÄ±p sonuÃ§larÄ± gÃ¶rÃ¼n.

### SeÃ§enek 2: Modeli SÄ±fÄ±rdan EÄŸitmek Ä°Ã§in
1. `Training.ipynb` dosyasÄ±nÄ± aÃ§Ä±n.
2. Dosyalar arasÄ±ndaki Flickr8k veri setini indirin.
3. TÃ¼m hÃ¼creleri sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±n.

---
**Model DosyalarÄ±:**
Modelin boyutu bÃ¼yÃ¼k olduÄŸu iÃ§in GitHub'a yÃ¼klenememiÅŸtir. `.h5` ve `.pkl` dosyalarÄ±nÄ± [Buraya Drive Linkini YapÄ±ÅŸtÄ±r] adresinden indirebilirsiniz.cells to generate captions for new images.

---
**Developer:** Eda VURAL
